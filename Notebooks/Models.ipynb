{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical vs. Semantic Search\n",
    "<p>Actual search applications can be complex and consist of several components in addition to the search engine itself: \n",
    "query auto-completion, query spell-correction, search filtering, integration with user preferences and profiles, boolean\n",
    "and/or regular expression search, etc. Here, however, we will focus only on the core search engine and its \n",
    "linguistic ability to match a natural language query to relevant fragments in the search corpus; in short, we will\n",
    "focus on the significance of the core engine algorithm within NLP.</p>\n",
    "<p>Search tests the ability of an NLP model to represent meaning at the <u>text</u> level: where by text\n",
    "we mean a sentence, or paragraph, or sequence of paragraphs; all these are generically referred to as documents, \n",
    "irrespective of size. A search engine is at its core, a similarity metric for the distance of documents in the search\n",
    "corpus and the user query, itself represented as a (mini) document. Search is organized in two stages: <ul>\n",
    "<li>at <u>index time</u>, each document in the search corpus is encoded into some kind of representation. </li>\n",
    "<li>at <u>run time</u>, the user query is also encoded into the same kind of representation, and compared on the fly\n",
    "to the representations in the corpus. The most similar corpus documents are returned as the search results.</li> </ul>\n",
    "<p>The encoding is typically a vector of features, representing the information in the text. Consequently, \n",
    "the similarity metric is one of the standard vector similarity metrics, such as cosine-similarity</p>\n",
    "<p>The traditional information-retrieval based search engine represents text as a <u>lexical frequency</u> vector.\n",
    "Lexical items are basically the words in the text: often just the 'content' words ('grammatical' words such as articles, \n",
    "pronouns, and other such, are ignored); sometimes words are lemmatized, i.e., replaced by their\n",
    "'root' form, to achieve more general representations: for ex., in English, 'loves', 'love', 'loved', 'loving', and even\n",
    "'lovable' or 'lovingly' could be unified as the same underlying 'lov' root. <br/>\n",
    "In this type of vector representation, each word in the vocabulary is a dimension, and its value is the TF/IDF of the word. \n",
    "That is, Term-Frequency over Document-Frequency: the frequency of the word in the text on hand, divided by the number \n",
    "of documents/texts the word occurs in. In practice, TF/IDF is more refined: log frequency is used for document frequency, \n",
    "and adjustments are made to compensate for the length of the document. <br/>\n",
    "Importantly, TF/IDF based model adopt the <u>bag-of-words</u> assumption: the (syntactic) order of words in the text\n",
    "is irrelevant. This is a helpful simplification, but of course can also be a serious limitation.<br/>\n",
    "<b>ElasticSearch</b> is the most popular implementation of the TF/IDF search framework.</p>\n",
    "<p>Recently, a new paradigm is emerging for search: <b>Semantic Search</b>, using Neural Network models. In this \n",
    "framework, the lexical identity of the words is not important. Words, or rather, words and sub-words (word fragments), are instead \n",
    "represented as vectors of semantic features. These (sub)word vectors are usually referred to as embeddings. The number \n",
    "of dimensions is not the size of the vocabulary anymore, but depends on the model implementation: typically 384 or 768. \n",
    "The model is usually trained for the Masked-Language-Model task (MLM): some 15 percent of the words in the training materials \n",
    "are hidden (=masked) and the model is trained to predict the missing words. The resulting features or dimensions of \n",
    "the word vectors are the weights the model learns through the MLM task. Although the model does not specifically assign \n",
    "a meaning to the features, they can be thought of as fine-grained semantic traits that make up the meaning of the words: \n",
    "e.g. features like 'is a person', 'has gender', 'is inanimate', etc. These models assign a vector to each word (or sub-word) in the text\n",
    "that is encoded; to provide a single vector representation of the whole text/document, the word vectors are typically\n",
    "averaged. </p> \n",
    "<p>State-of-the-art models for Semantic Search implement the <b>Transformers</b> neural architecture. These \n",
    "models are able to produce <b>contextual</b> word vectors: richer vector representations of words that reflect \n",
    "their semantic and syntactic relationships with the other words in the text. The averaged single vector encoding of \n",
    "a text is usually referred to as a 'sentence embedding'. </p>\n",
    "<p>At index time, all the texts in the document corpus to be searched, are encoded by the model into sentence\n",
    "vectors and stored. At runtime, the user query is converted into its own sentence embedding and compared with the stored \n",
    "embeddings using a vector distance metric. The most similar sentence embeddings from the document corpus are then returned \n",
    "as the search results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines and Experiments\n",
    "<p>When developing or choosing machine learning models to handle a task, it is helpful to extablish <b>baselines</b>, i.e., benchmark models \n",
    "that can be evaluated with iterative development, and provide development guidelines. </p>\n",
    "<p>We will setup two baselines: one for <b>ElasticSearch</b> with its standard TF/IDF information retrieval approach, and another one for Semantic Search using a Neural Network model. </p> \n",
    "<p>The latter is a state-of-the-art model built by fine-tuning a <b>Transformer</b> model by Microsoft ('MiniLM-L12-H384') on a very large set of sentence similarity datasets, \n",
    "covering a total of 1 billion sentences. This model is '<b>all-MiniLM-L12-v2</b>'. It is a fast, small (384 dimensional embeddings) yet powerful model for search applications.</p>\n",
    "<p>To summarize, the two approaches featured here differ in the following respects:\n",
    "<table><tr><th>Model</th><th>Word representation</th><th>Word order and dependencies</th><th>Vector size</th><th>Vector Feature Values</th></tr>\n",
    "    <tr><td>ElasticSearch 7.12</td><td>word or word-root, no internal structure</td><td>not represented</td><td>large, sparse vectors: size is entire vocabulary</td><td>TF/IDF</td></tr>\n",
    "    <tr><td>All-MiniLM-L12-v2</td><td>word-vectors of semantic features</td><td>encoded in word vectors</td><td>384 dimensional word embeddings, averaged into single text-embedding</td><td>neuron weights</td></tr>\n",
    "</table>\n",
    "<p>So, from the point of view of search, our focus is going to be to compare the pros and cons of lexical vs. semantic search, by setting up baselines for each, and \n",
    "furthermore, by developing a basic infrastructure to run and evaluate <b>experiments</b>. An experiment consists in running a search model with some specific configuration, \n",
    "evaluating its performance over a test set, while keeping track of the results. Experiments further develop and hopefully improve the baselines<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with Test Set\n",
    "<p>To compare models and their development iterations, it is necessary to develop a <u>Test Dataset</u>. </p>\n",
    "<p>A test set for a search application consists of a number of simulated user queries, paired with their search result, in the form of corpus snippets, their ids, and a human-assigned \n",
    "relevance grade. </p>\n",
    "<p>For our purposes here, which is to obtain an initial comparison of models and develop a methodology, we will setup a small set of test queries, say 30, and grade just the top 5 results for each. <br/>\n",
    "We will assign a numerical relevance grade of '3' to search results that are relevant; a grade of '2' to partially relevant search results; and a grade of '1' when a result is \n",
    "not relevant. The queries will be setup so that there is at least some content in the corpus that is relevant. We want to avoid the situation where the user query simply \n",
    "has no relevant match in the corpus. </p>\n",
    "<p>To evaluate each model and configuration against the Test Set, we will first run the model in the given configuration, collect the search results, grade them, and add them to the \n",
    "Test Set. Once all the (top 5) search results for each query are graded, we can produce evaluation metrics for the model. So this is an iterative process of running, \n",
    "grading, evaluating for each new model; the manual grading effort will tend to decrease as more and more graded search results are added to the test set. </p>\n",
    "<p>A note about our grading: search applications typically display search results by providing the document's title, and sometimes the tags, along with the portion of the \n",
    "document that is (supposed to be) most relevant to the query. Our preprocessed text include the text of the post's tags, and these are part of the searchable content. \n",
    "Consequently, when grading, we have implicitly considered the tags as part of the matched text. Some result that may not appear entirely relevant to the query, have sometimes\n",
    "gotten graded higher anticipating how they would be presented to the end-user.</p>\n",
    "<p>Below is an example of how we have set up the Test Set. We save this as 'data/health_search_results_true.csv:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>grade</th>\n",
       "      <th>id</th>\n",
       "      <th>snippet</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>4542:0</td>\n",
       "      <td>Why can I hear my heart beat louder after rigorous exercise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>5264:0</td>\n",
       "      <td>Is there such a thing as a hard heart beat? (as opposed to a fast heart beat)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>2</td>\n",
       "      <td>5264:5</td>\n",
       "      <td>Would this 'harder' heat beat burn more calories than a normal strength heart beat at the same bpm?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>825:0</td>\n",
       "      <td>Is it normal to feel your heart beat in your chest?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>2</td>\n",
       "      <td>20236:0</td>\n",
       "      <td>How does cold weather affect blood flow, heart beat, and heart attack?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>825:0</td>\n",
       "      <td>Is it normal to feel your heart beat in your chest?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>12427:3</td>\n",
       "      <td>The other day when i woke up i felt my heart beating hard, and i occasionally feel my heart beating without touching it with my hands.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>5264:2</td>\n",
       "      <td>After a heavy set of squats for instance I can hear my heart beating in my ears and feel it beating in my chest.</td>\n",
       "      <td>beating matched to beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>825:1</td>\n",
       "      <td>Is it normal for a person to at times feel their heart beat in their chest without actually placing their hand on their chest, while at other times not be able to (even though ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Is it ok to hear my heart beat?</td>\n",
       "      <td>3</td>\n",
       "      <td>4542:1</td>\n",
       "      <td>As I understand exercise increases hear rate. Why should an increase in hear rate feel like the heart is also beating louder (not just faster).</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             query  grade       id  \\\n",
       "0  Is it ok to hear my heart beat?      3   4542:0   \n",
       "1  Is it ok to hear my heart beat?      3   5264:0   \n",
       "2  Is it ok to hear my heart beat?      2   5264:5   \n",
       "3  Is it ok to hear my heart beat?      3    825:0   \n",
       "4  Is it ok to hear my heart beat?      2  20236:0   \n",
       "5  Is it ok to hear my heart beat?      3    825:0   \n",
       "6  Is it ok to hear my heart beat?      3  12427:3   \n",
       "7  Is it ok to hear my heart beat?      3   5264:2   \n",
       "8  Is it ok to hear my heart beat?      3    825:1   \n",
       "9  Is it ok to hear my heart beat?      3   4542:1   \n",
       "\n",
       "                                                                                                                                                                               snippet  \\\n",
       "0                                                                                                                          Why can I hear my heart beat louder after rigorous exercise   \n",
       "1                                                                                                        Is there such a thing as a hard heart beat? (as opposed to a fast heart beat)   \n",
       "2                                                                                  Would this 'harder' heat beat burn more calories than a normal strength heart beat at the same bpm?   \n",
       "3                                                                                                                                  Is it normal to feel your heart beat in your chest?   \n",
       "4                                                                                                               How does cold weather affect blood flow, heart beat, and heart attack?   \n",
       "5                                                                                                                                  Is it normal to feel your heart beat in your chest?   \n",
       "6                                               The other day when i woke up i felt my heart beating hard, and i occasionally feel my heart beating without touching it with my hands.   \n",
       "7                                                                     After a heavy set of squats for instance I can hear my heart beating in my ears and feel it beating in my chest.   \n",
       "8  Is it normal for a person to at times feel their heart beat in their chest without actually placing their hand on their chest, while at other times not be able to (even though ...   \n",
       "9                                      As I understand exercise increases hear rate. Why should an increase in hear rate feel like the heart is also beating louder (not just faster).   \n",
       "\n",
       "                     notes  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "5                      NaN  \n",
       "6                      NaN  \n",
       "7  beating matched to beat  \n",
       "8                      NaN  \n",
       "9                      NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_dir = \"../data\"\n",
    "true_results_file = os.path.join(data_dir, \"health_search_results_true.csv\")\n",
    "pd.options.display.max_colwidth = 180\n",
    "test_set_df = pd.read_csv(true_results_file, on_bad_lines='skip')\n",
    "test_set_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Exploring the search frameworks interactively\n",
    "<p>In addition to testing search frameworks through complete experiments, interactive testing is also available in this project. In interactive testing, frameworks can be tested and explored \n",
    "by submitting queries about health. </p>\n",
    "<p>The end-point for interactive testing is <b>get-search-results-interactive</b>. This is an example of interactive search, where the user is prompted to submit queries:</p>\n",
    "<pre>\n",
    "HealthSearch>  python3 health_exchange/main.py get-search-results-interactive \"./config/args_senttrans_1.json\"\n",
    "Usage: enter search query after prompt; enter 'q' to exit\n",
    "\n",
    "Query: are masks helpful to prevent covid?\n",
    "   1  [id: 21689:2 tags: covid-19 who-world-health-org]  I don't understand why wearing mask is not good way to prevent infection of COVID-19. Is it just because masks are out of stock?  (Score 0.83)\n",
    "   2  [id: 21459:5 tags: covid-19]  I understand that we should not wear masks because there is a shortage of them, they do not protect eyes, do not protect from touching face, etc.  (Score 0.81)\n",
    "   3  [id: 23489:2 tags: covid-19]  Early reports said that wearing a mask may not help to protect myself from other infected people, but it protects others from me (who might be infected).  (Score 0.8)\n",
    "   4  [id: 22939:3 tags: covid-19 prevention epidemiology covid-19-datasets]  Is this empirical evidence we should be wearing surgical masks?  (Score 0.79)\n",
    "   5  [id: 24411:4 tags: covid-19 face-mask-respirator]  So the question is does a shield help (to any significant degree) the wearer from spreading COVID-19 in the same way as a mask?  (Score 0.77)\n",
    "Query: \n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "As for the metrics, we provide the following: \n",
    "<ul><li><b>Relevance Table</b>: a table showing the percentage of relevant, partial, and non-relevant results</li>\n",
    "    <li><b>Discounted Cumulative Gain (DCG)</b>: this is an overall score that combines relevance and ranking, where ranking is the ability of the \n",
    "    search engine to return a more relevant result before a less relevant one. In DCG, the relevance score of each search result is 'discounted' by its ranking, or \n",
    "    position, in the result set. So a relevant search result returned as the first answer will count more than a relevant search result returned as the second, and so forth.</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Infrastructure\n",
    "<p>Experiments consist in running a search model against a Test Set of simulated user queries, and extracting evaluation metrics.</p>\n",
    "<p>Experiments center around a configuration: for us, a json file that include settings like the experiment name, the framework (Elasticsearch or Sentence Transformer), and various hyperparameters and preprocessing choices, as needed.</p>\n",
    "<p>We perform experiments in three phases:\n",
    "<ol><li>create a search index from the search corpus and store it </li>\n",
    "    <li>run the model on the simulated user queries in the Test Set, and generate search results using the search index</li>\n",
    "    <li>extract search metrics after manually grading the search results</li>\n",
    "</ol>\n",
    "<p>Finally, we need a way to keep track of our experiments and their results, so that we can proceed with iterative development of the baselines. \n",
    "<p>To implement this infrastructure and manage experiments, we therefore need to put in place the following components:\n",
    "<ul><li>Python functions that execute each phase, depending on the framework of the experiment</li>\n",
    "    <li>a convenient interface to execute these functions. A CLI (Command Line Interface) can suffice for this project (though in real life, a Rest implementation would be preferable)</li>\n",
    "    <li>a framework to store, keep track, and manage all the experiments. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Configurations\n",
    "<p>Let's start with the experiment configurations. Here are the contents of the json files for the two baselines:</p>\n",
    "<pre>\n",
    "{\n",
    "    \"model_type\": \"elasticsearch\",\n",
    "    \"index_name\": \"healthex__tags_snippet_tttf\",\n",
    "    \"run_name\": \"es_baseline\",\n",
    "    \"prep_lower\": true,\n",
    "    \"prep_skipw\": true,\n",
    "    \"prep_stem\": false,\n",
    "    \"prep_remove_punct\": true,\n",
    "    \"prep_prefix_col\": \"Tags\",\n",
    "    \"prep_col\": \"Snippet\",\n",
    "    \"prep_max_words_per_snippet\": 30,\n",
    "    \"num_search_results\": 5\n",
    "}\n",
    "{\n",
    "    \"model_type\": \"sent_transformer\",\n",
    "    \"model_filepath\": \"./Models/sentence-transformers_all-MiniLM-L12-v2\",\n",
    "    \"run_name\": \"sent_trans_baseline\",\n",
    "    \"prep_lower\": true,   \n",
    "    \"prep_skipw\": false,\n",
    "    \"prep_stem\": false,\n",
    "    \"prep_remove_punct\": false,\n",
    "    \"prep_prefix_col\": \"Tags\",\n",
    "    \"prep_col\": \"Snippet\",\n",
    "    \"prep_max_words_per_snippet\": 30,\n",
    "    \"num_search_results\": 5\n",
    "}\n",
    "</pre>\n",
    "<p>These are rather minimal configurations, but sufficient for this project. In real life, we would want a number of additional settings, such as json strings for the (field) \"mappings\", \"settings\", \n",
    "and \"query\" elements of the Elasticsearch configuration, and others. For Transformer models, one may want to configure the max sequence length (in tokens) of the inputs, the method for producing sentence embeddings from the final layers of the Transformer model, whether we encode individual texts or pairs of texts (this is an option with Transformer models), and many other hyperparameters.</p> <p>This does get quite involved, and for simplicity we have chosen here a very high-level implementation of Transformers, the <b>Sentence-Transformers</b> Python library, using the Pytorch framework. This implementation is curated by Nils Reimers and hosted at https://www.sbert.net/ (cf. Reimers, Nils and Gurevych, Iryna, \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\", 2019, https://arxiv.org/abs/1908.10084); it makes using these complex models very easy, by hiding a lot of the details. </p>\n",
    "<p>Furthermore, we are not training a Transformer model in this project; instead we are using a ready-made, pre-trained and already fine tuned model, the 'all-MiniLM-L12-v2', which is a good fit for the non-technical language of the StackExchange Health posts. So we can dispense with a long list of training hyperparams.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry points for running the Experiments\n",
    "<p>The python functions to drive the experiment phases are detailed in the 'main.py' file of the 'health_exchange' module. For the CLI interface, we use the 'typer' package and annotate the entry-point\n",
    "functions. This conveniently allows at least members of a development team to run the experiments without having to delve into the python code. </p>\n",
    "<p>Here is a summary of the high-level steps for the essential CLI entry points:\n",
    "<ul><li>create-index:\n",
    "        <ul><li>Elasticsearch:</li>\n",
    "                <ul><li>connect to Elasticsearch server</li>\n",
    "                    <li>preprocess the raw text in the search corpus, storing in a csv the mapping the preprocessed texts to the raw text and id, so we can display the latter in \n",
    "                        a user-friendly way in the search results</li>\n",
    "                    <li>add the preprocessed text to the search index</li>\n",
    "                </ul>\n",
    "            <li>Sentence Transformer:</li>\n",
    "                <ul><li>load the Transformer model from a local folder (\"health_exchange/Models\")</li>\n",
    "                    <li>preprocess the raw text in the search corpus, storing in a csv the mapping the preprocessed texts to the raw text, so we can \n",
    "                        display the latter in a user-friendly way in the search results</li>\n",
    "                    <li>encode the preprocessed text into sentence embeddings and store in a compressed ('pkl') file. Note that hardly any pre-processing needs to be done. </li>\n",
    "                    <li>additionally, we want to store the preprocessed text into a file, so that we can map the embeddings to the text snippets.</li>\n",
    "                </ul>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>run-test-queries\n",
    "        <ul><li>Elasticsearch:</li>\n",
    "                <ul><li>connect to Elasticsearch server</li>\n",
    "                    <li>retrieve the mapping preprocessed-text to raw-text</li>\n",
    "                    <li>preprocess the test query, and get results from the Elasticsearch server</li>\n",
    "                    <li>map the results to the raw-text along with the snippet ids, and store into a results file</li>\n",
    "                </ul>\n",
    "            <li>Sentence Transformer:</li>\n",
    "                <ul><li>retrieve the mapping preprocessed-text to raw-text, the file with the corpus embeddings, and the file with the (prepped) text snippets</li>\n",
    "                    <li>create an embedding for the query</li>\n",
    "                    <li>compare the query embedding with the stored corpus embeddings, and get the indices of the most similar corpus embeddings</li>\n",
    "                    <li>using the stored mappings and text snippets, flesh out the search results in a user-friendly format, and store in a results file.\n",
    "                </ul>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>evaluate-run\n",
    "        <ul><li>this step is the same for Elasticsearch and Sentence Transformer:</li>\n",
    "                <ul><li>NOTE: prior to running this entry-point, the search results need to be manually graded for relevance, and the graded results\n",
    "                    stored in a csv file.</li>\n",
    "                    <li>using the \"true\" results file, compute and publish metrics for the search results file and other stats</li>\n",
    "                </ul>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<p>As can be seen, to ensure artifact persistence between entry-points, the artifact data is simply written to local files. While this serves the purposes of this project, \n",
    "in real life a more principled solution would need to be adopted, obviously. There are a number of frameworks, from Redis to MongoDB and others, that can be used for this \n",
    "purpose. Same applies to storing Transformer models.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Tracking with MLFLow\n",
    "As featured in \"MadeWithML\" (Goku Mohandas, https://madewithml.com/, 2022), we use MLFlow as the framework for tracking and managing experiments. The python client \n",
    "allows us to pass the configuration parameters, the artifacts, and the metrics to MLFlow, and to display them by running a server with a nice GUI interface. \n",
    "<p>The python code for the MLFlow client is integrated into the code for the experiments entry-points. To start the MLFlow server, point your browser to \"http://localhost:8000/\". </p>\n",
    "<p>To illustrate, here is a screenshot of the opening page after running the experiments:</p>\n",
    "<p><img src=\"../images/mlflow_main.png\" alt=\"main\" width=\"2000\"></p>\n",
    "<p>Next, by clicking on the 'es_baseline_run_queries' run name, you can access the artifacts: specifically, the search results (ungraded):\n",
    "<p><img src=\"../images/mlflow_elastic_results.png\" alt=\"results\" width=\"2000\"></p>\n",
    "<p>Note: clicking on the larger file '...info.json' may freeze the UI -- best not.\n",
    "<br/>As always, refer to \"COMMANDS.md\" for a description of the commands to run.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Result Evaluation for Baselines\n",
    "<p>We have setup two baseline experiments, \"elastic_1\" and \"senttrans_1\". Additionally, we feature another experiment for Elasticsearch, \"elastic_1.1\". \n",
    "The latter is a modification of \"elastic_1\" by adding stemming to the preprocessing. </p>\n",
    "<p>Once the suite of commands \"create-index\", \"run-test-queries\", and \"evaluate-run\", are executed, these experiments produce the following evaluation metrics:</p>\n",
    "<h4> Elasticsearch (args_elastic_1):</h4>\n",
    "<pre>\n",
    "{\n",
    "    \"percent relevant\": 44.67,\n",
    "    \"percent partial\": 14.67,\n",
    "    \"percent notrelevant\": 40.67,\n",
    "    \"average dcg\": 2.515,\n",
    "    \"total queries\": 30,\n",
    "    \"total ungraded\": 0,\n",
    "    \"total results\": 150\n",
    "}\n",
    "</pre>\n",
    "<h4> Elasticsearch (args_elastic_1.1)</h4>\n",
    "<pre>\n",
    "{\n",
    "    \"percent relevant\": 44.67,\n",
    "    \"percent partial\": 19.33,\n",
    "    \"percent notrelevant\": 36.0,\n",
    "    \"average dcg\": 2.592,\n",
    "    \"total queries\": 30,\n",
    "    \"total ungraded\": 0,\n",
    "    \"total results\": 150\n",
    "}\n",
    "</pre>\n",
    "<p></p>\n",
    "<h4> Sentence Transformers (args_senttrans_1):</h4>\n",
    "<pre>\n",
    "{\n",
    "    \"percent relevant\": 63.33,\n",
    "    \"percent partial\": 18.0,\n",
    "    \"percent notrelevant\": 18.67,\n",
    "    \"average dcg\": 3.144,\n",
    "    \"total queries\": 30,\n",
    "    \"total ungraded\": 0,\n",
    "    \"total results\": 150\n",
    "}\n",
    "</pre>\n",
    "<p>As can be seen, the 'senttrans_1' experiment achieves the best accuracy scores. On the other hand, experiment \"elastic_1.1\" does not really improve the accuracy of \"elastic_1\" baseline. <br/>\n",
    "We will comment on these results below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: a (subjective) comparison of Elasticsearch vs. Semantic Search with Transformers\n",
    "<p>This project is meant as a preliminary investigation of two popular search frameworks, Elasticsearch and Semantic Search, as language models,\n",
    "that is, as models of a human's language competence: specifically, the ability to understand language as text. The Test Set assembled here is \n",
    "strongly slanted toward natural language understanding: most of the questions are relatively long, syntactically well formed sentences. There are \n",
    "just a few keyword-style questions</p>\n",
    "<p>From this point of view, Semantic Search using Transformers model comes out clearly as superior. The sense one gets in reviewing the search results \n",
    "for the Test Set is that the 'lexical' assumptions of Elasticsearch prevent these models from adequately representing the overall meaning of texts. \n",
    "Text meaning is clearly more than the sum of the words (cf. Elasticsearch bag-of-words assumption). In fact, Elasticsearch comes short in the\n",
    "following respects:\n",
    "<ul><li>It does not represent the main intent of the query: what are the most important words that need to be matched, as opposed to less \n",
    "        important ones. Linguists refer to this as the 'theme-rheme' or 'topic-comment' structure of sentences. Most of the irrelevant search \n",
    "        results produced by Elasticsearch derive from getting matches only for words that don't convey the main focus of the question.</li>\n",
    "    <li>It identifies word matches in a rather superficial way (cf. 'lexical' assumption), by the accidental shape of words. Standardizing text \n",
    "        in various ways, such as removing skip-words, lower-casing, removing punctuation, does not really help. Actually it may make the problem worse; \n",
    "        as can be seen in the 'args' configuration for experiment 'elastic_1.1', stemming the words further lowers the overall accuracy of the model.\n",
    "        Related to this, there is no built-in provision for synonymity. Although Elasticsearch allows for importing synonym lists, this approach\n",
    "        is laborious to implement and especially, maintain, and, like stemming, can sometimes do more harm than good. Synonyms are highly domain-specific.\n",
    "    <li>It does not represent the relationships between words in the text, both syntactically (=word order) and semantically</li>\n",
    "</ul></p>\n",
    "<p>Conversely, these are the respects in which Transformers provide a superior representation:\n",
    "<ul><li>Models like 'all-MiniLM-L12-v2' are trained on a very large (1 billion) paraphrase pairs, including NLI (=Natural Language Inference) \n",
    "        triplets, where they learn which sentences are in an paraphrase or inferential relationship. Although Transformers are not perfect \n",
    "        at identifying the intent of the user queries, they make some definite strides in this respect.</li>\n",
    "    <li>The lexical shape of words is largely irrelevant to Transformers models, since words (and sub-words) are immediately mapped\n",
    "        to their base vectors: these are representations of the co-occurrence patterns of the words, hence they are inherently \n",
    "        semantic representations. Words that are natural synonyms tend to occur is the same contexts, and their base vectors end \n",
    "        up being similar. So, synonymity comes automatically with word-vectors. Note that with these models, it is not necessary \n",
    "        (and can may actually be harmful) to standardize the text. Furthermore, the tokenization approach used by Trasformers, where\n",
    "        many words are split into sub-words, depending on relative frequency, automatically makes similar representations for \n",
    "        word variants. But importantly, all the text can be modelled, including punctuation and skip-words, thus obtaining a \n",
    "        richer representation of the text.</li>\n",
    "    <li>Transformers, via their 'attention heads' are able to capture the dependencies between words in the text. They also\n",
    "        keep track of the order of the words. The final word-vectors produced by Transformers reflect their syntactic and \n",
    "        semantic feature in the text, and are therefore 'contextualized' word-vectors. A model such as 'all-MiniLM-L12-v2'\n",
    "        successively produces 12 vector representations of the base vectors, each capturing a different kind of relationship\n",
    "        between words.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the best approach for Search?\n",
    "<p>Although Transformers are better language models, this does not mean they are always the best solution for search. As noted, search applications \n",
    "tend to be complex, and linguistic accuracy is only one of the aspects in which to evaluate a search application; although admittedly, is a very\n",
    "fun and interesting one. </p>\n",
    "<p>Elasticsearch is still a very popular framework, in part because it's highly configurable to suit the specific needs of applications. Here, we \n",
    "have featured a very basic, actually simplistic, configuration for Elasticsearch, one that hardly does justice to its power. Compared to Elasticsearch, \n",
    "our version of Semantic Search may seem like a 'black box'. In fact, Semantic Search with neural network models tends to suffer from its own \n",
    "limitations, including:\n",
    "<ul><li>Speed of indexing and index footprint</li>\n",
    "    <li>Lack of configurability: while as we have seen, it's very easy to setup a sophisticated Semantic Search using a pre-trained model and \n",
    "    the SentenceTransformers library, it's quite hard to effect specific changes in the search results. </li>\n",
    "    <li>Difficulty with 'literal' matches: because Word-Vectors models do not maintain a representation of the outer aspect of text, it's \n",
    "    difficult to guarantee a 'literal' match, as when people encase a text string in double quotes in the query. Typical use-case is exact matching \n",
    "    of error messages.</li>\n",
    "    <li>Difficulty with numbers: exact matching of multi-digit numbers, versions, and codes with a numerical part, is often imprecise with \n",
    "    these models. This may be because owing to the endless variety in numerical expressions, it is difficult for the model to \n",
    "    have sufficient number of training examples to indentify a specific number and its role in the meaning of the text.</li>\n",
    "    <li>Difficulty with very short keyword-style questions: there is no provision on how to interpret a single keyword question -- for example,\n",
    "    as a request for a definition, or an introductory explanation. In fact, the lack of linguistic context tends to retrieve results where \n",
    "    the keyword is matched along the least informative content. </li>\n",
    "</ul>\n",
    "<p>Despite its prowess with natural language understanding, these limitations indicate that currently, semantic search via Bert-like Transformers\n",
    "models may not yet be a wholesale solution for search. These limitations may however, be removed in future developments: as it has been the case with \n",
    "OpenAI Chat-GPT, additional training with reinforcement learning and input from human users, may well produce semantic search AI applications that \n",
    "are much more tuned to human expectations. More immediately, and in part, some of these limitations may be overcome by training additional network \n",
    "agents to filter the search results produced by the search. For example, a classifier that could predict if a search result provides a definition, \n",
    "or explains an error message could be invoked when the user question is keyword-like or is an error code. </p>\n",
    "<p>Alternatively, one emerging approach to alleviate the limitations consists in blending Elasticsearch and Semantic Search. Recent versions of Elasticsearch \n",
    "allow sentence vectors to be used as a type of search field, and integrated into the search alongside more traditional field representations. \n",
    "This may allow for longer, 'natural language' user questions to benefit from the power of contextualized word vectors, whereas short, keyword-like \n",
    "questions can receive the standard TF/IDF vector representation and IR similarity metric. Additionally, the distributed infrastrure and \n",
    "other facilities of Elasticsearch can be leveraged in this approach. \n",
    "</o>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples from the Test Set\n",
    "To make the above point a bit more concrete, here are some examples of search results, along with an analysis:\n",
    "<ul><li>Elasticsearch, missing match to the focus of the query: <p>\n",
    "        <table><tr><th>Query</th><th>Grade</th><th>Id</th><th>Result</th><th>Notes</th></tr>\n",
    "               <tr><td>what are negative eye powers?</td><td>1</td><td>20794:3</td><td>\"Does it not let the muscles they eye use relax? If so, why not?\"</td><td>missing focus: negative powers</td></tr>\n",
    "               <tr><td>can ultrasound cause damage?</td><td>1</td><td>18108:0</td><td>Does walking daily cause knee joint damage?</td><td>missing focus: ultrasound</td></tr>\n",
    "               <tr><td>gallstones relief</td><td>1</td><td>5664:0</td><td>Why does exercise relief stomach pain/bloating</td><td>missing focus: gallstones</td></tr>\n",
    "               <tr><td>toothpaste with or without fluoride? Pros and cons?</td><td>1</td><td>3616:0</td><td>What are the pros and cons of personalized medicine?</td><td>missing focus: fluoride toothpaste</td></tr>\n",
    "        </table>\n",
    "        <p></p>\n",
    "    </li>\n",
    "    <li>Elasticsearch, wrong meaning of word: <p>\n",
    "        <table><tr><th>Query</th><th>Grade</th><th>Id</th><th>Result</th><th>Notes</th></tr>\n",
    "               <tr><td>is it ok to go to the pool after I had a piercing?</td><td>1</td><td>11846:6</td><td>\"A good example is playing pool. When I look at the ball, [...] and am unable to make the shot.\"</td><td>wrong sense of 'pool'</td></tr>\n",
    "        </table>\n",
    "        <p></p>\n",
    "    </li>\n",
    "    <li>Sentence Transformer, synonym matching: <p>\n",
    "        <table><tr><th>Query</th><th>Grade</th><th>Id</th><th>Result</th><th>Notes</th></tr>\n",
    "               <tr><td>How many calories do I have to burn to lose 1 Kilogram in weight?</td><td>3</td><td>797:0</td><td>Does 3500 calories really equal a pound?</td><td>'Kilogram' ~ 'pound'</td></tr>\n",
    "               <tr><td>what are negative eye powers?</td><td>3</td><td>3355:0</td><td>What does eye power -6 means and how close to blindness is it?</td><td>'negative' ~ '-'</td></tr>\n",
    "               <tr><td>what are the effects of drinking coffee?</td><td>3</td><td>17497:0</td><td>Did science backtrack regarding coffee causing dehydration?</td><td>'effects' ~ 'cause'</td></tr>\n",
    "        </table>\n",
    "        <p></p>\n",
    "    </li>\n",
    "    <li>Sentence Transformer, word variation: <p>\n",
    "        <table><tr><th>Query</th><th>Grade</th><th>Id</th><th>Result</th><th>Notes</th></tr>\n",
    "               <tr><td>is it ok to go to the pool after I had a piercing?</td><td>1</td><td>5733:1</td><td>I am a male and I am considering to get one of my nipples pierced</td><td>'piercing' ~ 'pierced'</td></tr>\n",
    "               <tr><td>How many calories do I have to burn to lose 1 Kilogram in weight?</td><td>3</td><td>5394:0</td><td>\"How many Calories Deficit Equals 1 KG Loss, approximately\"</td><td>'Kilogram' ~ 'KG', 'lose' ~ 'loss'</td></tr>\n",
    "               <tr><td>chicken pox</td><td></td><td>5120:0</td><td>Is getting the chickenpox vaccination twice in a month harmful?  (topics: vaccination, chickenpox)</td><td>'chicken pox' ~ 'chickenpox'</td></tr>\n",
    "        </table>\n",
    "        <p></p>\n",
    "    </li>\n",
    "    <li>Sentence Transformer, single keyword queries: <p>\n",
    "        <table><tr><th>Query</th><th>Grade</th><th>Id</th><th>Result</th><th>Notes</th></tr>\n",
    "               <tr><td>covid</td><td></td><td>22823:14</td><td>Or something else?  (topics: covid-19)</td><td>uninformative snippet, correct topic tag</td></tr>\n",
    "               <tr><td>antibiotics</td><td></td><td>17787:5</td><td>I tried to look up the answer but besides some forum-posts there doesn't seem to be any kind of \"official\" statement (from a pharma company or something equivalent) about how to handle such a situation (or at least I wasn't able to find it).  (topics: medications, antibiotics)</td><td>uninformative snippet, correct topic tag</td></tr>>\n",
    "        </table>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ced34d1d70fb0feab6769f7117f78206a3fb5e67744e92bd124074afcdcb1014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
